{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0/U0uuW6BosNJhgP2F/kK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joybratas1/Credit-Card-Fraud-Project/blob/main/CCFraud_%20Decision%20Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK_X_jd6mAjZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter # counter takes values returns value_counts dictionary\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from plotly.offline import init_notebook_mode\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8RJyBxmDrKN"
      },
      "source": [
        "pip install opendatasets --upgrade --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YYbFjfXDtX9",
        "outputId": "f8e229c3-2acb-442d-b8b5-d2bffa695df1"
      },
      "source": [
        "import opendatasets as od\n",
        "url_l='https://www.kaggle.com/mlg-ulb/creditcardfraud'\n",
        "od.download(url_l)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: joybratasarkar\n",
            "Your Kaggle Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0.00/66.0M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading creditcardfraud.zip to ./creditcardfraud\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 66.0M/66.0M [00:01<00:00, 44.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyr3WA79DvB8",
        "outputId": "e673f5be-325d-4575-a894-daeb4ae4ca39"
      },
      "source": [
        "file_name='/content/creditcardfraud/creditcard.csv'\n",
        "df= pd.read_csv(file_name)\n",
        "df.dataframeName = 'European Credit card Fraud data.csv'\n",
        "nRow, nCol = df.shape\n",
        "print('There are {} rows and {} columns in our Dataset'.format(nRow,nCol))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 284807 rows and 31 columns in our Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aq90NTqDzbJ",
        "outputId": "d0e0a6da-7060-40c0-9c59-047b99c392f9"
      },
      "source": [
        "def reduce_memory(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = reduce_memory(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 67.36 MB\n",
            "Memory usage after optimization is: 17.11 MB\n",
            "Decreased by 74.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNJsVG4ID2Vy",
        "outputId": "d8665082-a085-4ce8-f7b9-bcc8678bfcea"
      },
      "source": [
        "vc = df['Class'].value_counts().to_frame().reset_index()\n",
        "vc['percent'] = vc[\"Class\"].apply(lambda x : round(100*float(x) / len(df), 2))\n",
        "#vc = vc.rename(columns = {\"index\" : \"Target\", \"Class\" : \"Count\"})\n",
        "\n",
        "print('No Frauds Cases are ', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset i.e.', vc.iloc[0,1])\n",
        "print('Frauds Cases are', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset i.e.', vc.iloc[1,1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Frauds Cases are  99.83 % of the dataset i.e. 284315\n",
            "Frauds Cases are 0.17 % of the dataset i.e. 492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trFmDUE2D5u8"
      },
      "source": [
        "# Dropping the Time column\n",
        "df.drop('Time', axis=1, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NRQNGNjD8eC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMrR6pw0D_Sm"
      },
      "source": [
        "y = df.Class\n",
        "X = df.drop('Class', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100,stratify=y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkvbX6wvEBQG"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "rob_scaler = RobustScaler()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "ZFIGTibQEC8v",
        "outputId": "9fac171a-0c42-40b6-b615-e39889f71923"
      },
      "source": [
        "X_train['Amount'] = rob_scaler.fit_transform(X_train['Amount'].values.reshape(-1,1))\n",
        "\n",
        "X_train"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>276544</th>\n",
              "      <td>2.019531</td>\n",
              "      <td>-0.099060</td>\n",
              "      <td>-1.123047</td>\n",
              "      <td>0.461670</td>\n",
              "      <td>-0.167358</td>\n",
              "      <td>-1.240234</td>\n",
              "      <td>0.219849</td>\n",
              "      <td>-0.311279</td>\n",
              "      <td>0.829590</td>\n",
              "      <td>-0.090515</td>\n",
              "      <td>-0.836426</td>\n",
              "      <td>0.263184</td>\n",
              "      <td>-0.536133</td>\n",
              "      <td>0.456299</td>\n",
              "      <td>0.231689</td>\n",
              "      <td>-0.322021</td>\n",
              "      <td>-0.268066</td>\n",
              "      <td>-0.595703</td>\n",
              "      <td>0.176147</td>\n",
              "      <td>-0.260010</td>\n",
              "      <td>-0.253662</td>\n",
              "      <td>-0.625488</td>\n",
              "      <td>0.289551</td>\n",
              "      <td>-0.001698</td>\n",
              "      <td>-0.139893</td>\n",
              "      <td>-0.585938</td>\n",
              "      <td>-0.016449</td>\n",
              "      <td>-0.048065</td>\n",
              "      <td>-0.071716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168089</th>\n",
              "      <td>-0.815918</td>\n",
              "      <td>-0.408203</td>\n",
              "      <td>-1.699219</td>\n",
              "      <td>-0.622070</td>\n",
              "      <td>0.273438</td>\n",
              "      <td>-0.498535</td>\n",
              "      <td>3.472656</td>\n",
              "      <td>-0.622559</td>\n",
              "      <td>-1.340820</td>\n",
              "      <td>-0.738281</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.307129</td>\n",
              "      <td>-0.033081</td>\n",
              "      <td>0.944336</td>\n",
              "      <td>-1.416992</td>\n",
              "      <td>-0.429688</td>\n",
              "      <td>-0.626465</td>\n",
              "      <td>0.209351</td>\n",
              "      <td>0.271973</td>\n",
              "      <td>0.940430</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>1.292969</td>\n",
              "      <td>0.696289</td>\n",
              "      <td>-0.340088</td>\n",
              "      <td>0.153442</td>\n",
              "      <td>0.866699</td>\n",
              "      <td>-0.099182</td>\n",
              "      <td>0.199829</td>\n",
              "      <td>6.621094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91651</th>\n",
              "      <td>-1.185547</td>\n",
              "      <td>1.182617</td>\n",
              "      <td>1.567383</td>\n",
              "      <td>-0.001388</td>\n",
              "      <td>-0.005512</td>\n",
              "      <td>-0.770508</td>\n",
              "      <td>0.738281</td>\n",
              "      <td>-0.090759</td>\n",
              "      <td>-0.246582</td>\n",
              "      <td>0.231323</td>\n",
              "      <td>0.611328</td>\n",
              "      <td>0.958984</td>\n",
              "      <td>1.365234</td>\n",
              "      <td>-0.294678</td>\n",
              "      <td>0.969238</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>-0.064758</td>\n",
              "      <td>-1.189453</td>\n",
              "      <td>-0.559082</td>\n",
              "      <td>0.210815</td>\n",
              "      <td>-0.252686</td>\n",
              "      <td>-0.234619</td>\n",
              "      <td>0.166748</td>\n",
              "      <td>0.623535</td>\n",
              "      <td>-0.245361</td>\n",
              "      <td>0.008331</td>\n",
              "      <td>-0.141479</td>\n",
              "      <td>-0.355225</td>\n",
              "      <td>-0.141235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258071</th>\n",
              "      <td>1.817383</td>\n",
              "      <td>-0.727539</td>\n",
              "      <td>-0.291504</td>\n",
              "      <td>0.459473</td>\n",
              "      <td>-0.895996</td>\n",
              "      <td>-0.273438</td>\n",
              "      <td>-0.683594</td>\n",
              "      <td>0.106567</td>\n",
              "      <td>1.052734</td>\n",
              "      <td>0.166870</td>\n",
              "      <td>0.730469</td>\n",
              "      <td>0.756348</td>\n",
              "      <td>-0.583008</td>\n",
              "      <td>0.108887</td>\n",
              "      <td>-0.273193</td>\n",
              "      <td>0.417236</td>\n",
              "      <td>-0.588867</td>\n",
              "      <td>0.466064</td>\n",
              "      <td>-0.098816</td>\n",
              "      <td>-0.109314</td>\n",
              "      <td>0.287598</td>\n",
              "      <td>0.865723</td>\n",
              "      <td>0.091492</td>\n",
              "      <td>0.070007</td>\n",
              "      <td>-0.322266</td>\n",
              "      <td>0.589355</td>\n",
              "      <td>-0.038666</td>\n",
              "      <td>-0.049530</td>\n",
              "      <td>0.670898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167236</th>\n",
              "      <td>-1.670898</td>\n",
              "      <td>-7.312500</td>\n",
              "      <td>-2.699219</td>\n",
              "      <td>0.667480</td>\n",
              "      <td>-3.021484</td>\n",
              "      <td>0.248047</td>\n",
              "      <td>1.533203</td>\n",
              "      <td>-0.518555</td>\n",
              "      <td>-0.097412</td>\n",
              "      <td>-0.171631</td>\n",
              "      <td>-0.779297</td>\n",
              "      <td>-0.744141</td>\n",
              "      <td>0.065796</td>\n",
              "      <td>0.137939</td>\n",
              "      <td>0.922852</td>\n",
              "      <td>1.761719</td>\n",
              "      <td>0.045166</td>\n",
              "      <td>-0.804688</td>\n",
              "      <td>-0.130981</td>\n",
              "      <td>4.019531</td>\n",
              "      <td>1.234375</td>\n",
              "      <td>-1.047852</td>\n",
              "      <td>-1.350586</td>\n",
              "      <td>0.794434</td>\n",
              "      <td>-1.232422</td>\n",
              "      <td>-0.680664</td>\n",
              "      <td>-0.369873</td>\n",
              "      <td>0.313232</td>\n",
              "      <td>27.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194533</th>\n",
              "      <td>-0.917480</td>\n",
              "      <td>0.855469</td>\n",
              "      <td>1.515625</td>\n",
              "      <td>-0.220703</td>\n",
              "      <td>0.747559</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>0.827637</td>\n",
              "      <td>0.281494</td>\n",
              "      <td>0.400879</td>\n",
              "      <td>-1.066406</td>\n",
              "      <td>-2.439453</td>\n",
              "      <td>-0.765137</td>\n",
              "      <td>-1.608398</td>\n",
              "      <td>-0.233643</td>\n",
              "      <td>-1.497070</td>\n",
              "      <td>0.011734</td>\n",
              "      <td>-0.457764</td>\n",
              "      <td>-0.414795</td>\n",
              "      <td>-0.072083</td>\n",
              "      <td>-0.274170</td>\n",
              "      <td>-0.583984</td>\n",
              "      <td>-1.673828</td>\n",
              "      <td>-0.248779</td>\n",
              "      <td>-0.213989</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>-1.054688</td>\n",
              "      <td>-0.068481</td>\n",
              "      <td>0.048981</td>\n",
              "      <td>0.173462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163532</th>\n",
              "      <td>-0.818848</td>\n",
              "      <td>-0.653809</td>\n",
              "      <td>1.685547</td>\n",
              "      <td>-1.561523</td>\n",
              "      <td>0.357422</td>\n",
              "      <td>1.305664</td>\n",
              "      <td>0.371826</td>\n",
              "      <td>-0.086060</td>\n",
              "      <td>-0.349609</td>\n",
              "      <td>0.156616</td>\n",
              "      <td>-0.675293</td>\n",
              "      <td>-1.141602</td>\n",
              "      <td>-0.944336</td>\n",
              "      <td>-0.998047</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.894043</td>\n",
              "      <td>1.537109</td>\n",
              "      <td>-2.703125</td>\n",
              "      <td>0.337891</td>\n",
              "      <td>0.072693</td>\n",
              "      <td>0.248169</td>\n",
              "      <td>1.356445</td>\n",
              "      <td>-0.603516</td>\n",
              "      <td>-1.038086</td>\n",
              "      <td>0.609863</td>\n",
              "      <td>0.318604</td>\n",
              "      <td>-0.277344</td>\n",
              "      <td>-0.461914</td>\n",
              "      <td>1.102539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47169</th>\n",
              "      <td>0.984375</td>\n",
              "      <td>-0.951660</td>\n",
              "      <td>0.760742</td>\n",
              "      <td>0.729492</td>\n",
              "      <td>-1.429688</td>\n",
              "      <td>-0.353271</td>\n",
              "      <td>-0.542480</td>\n",
              "      <td>-0.063049</td>\n",
              "      <td>-0.419434</td>\n",
              "      <td>0.629883</td>\n",
              "      <td>-0.971191</td>\n",
              "      <td>-0.123718</td>\n",
              "      <td>0.026550</td>\n",
              "      <td>-0.172363</td>\n",
              "      <td>0.361328</td>\n",
              "      <td>-1.416016</td>\n",
              "      <td>-0.041656</td>\n",
              "      <td>1.488281</td>\n",
              "      <td>-1.164062</td>\n",
              "      <td>-0.233032</td>\n",
              "      <td>-0.148315</td>\n",
              "      <td>-0.163452</td>\n",
              "      <td>-0.190674</td>\n",
              "      <td>0.378174</td>\n",
              "      <td>0.456543</td>\n",
              "      <td>-0.239014</td>\n",
              "      <td>0.045746</td>\n",
              "      <td>0.061768</td>\n",
              "      <td>2.070312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138367</th>\n",
              "      <td>0.699707</td>\n",
              "      <td>-1.557617</td>\n",
              "      <td>0.286865</td>\n",
              "      <td>0.349609</td>\n",
              "      <td>-1.519531</td>\n",
              "      <td>-0.535645</td>\n",
              "      <td>-0.117676</td>\n",
              "      <td>-0.177246</td>\n",
              "      <td>-0.468506</td>\n",
              "      <td>0.452393</td>\n",
              "      <td>-0.967285</td>\n",
              "      <td>-0.115479</td>\n",
              "      <td>-0.277588</td>\n",
              "      <td>-0.071106</td>\n",
              "      <td>-0.190430</td>\n",
              "      <td>-1.633789</td>\n",
              "      <td>0.319336</td>\n",
              "      <td>0.736816</td>\n",
              "      <td>-0.609863</td>\n",
              "      <td>0.116943</td>\n",
              "      <td>-0.456787</td>\n",
              "      <td>-1.458984</td>\n",
              "      <td>-0.134644</td>\n",
              "      <td>0.368408</td>\n",
              "      <td>0.086121</td>\n",
              "      <td>0.273682</td>\n",
              "      <td>-0.065369</td>\n",
              "      <td>0.075745</td>\n",
              "      <td>4.429688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>-0.351318</td>\n",
              "      <td>1.183594</td>\n",
              "      <td>0.530762</td>\n",
              "      <td>0.543945</td>\n",
              "      <td>0.798340</td>\n",
              "      <td>-0.804688</td>\n",
              "      <td>1.563477</td>\n",
              "      <td>-0.936035</td>\n",
              "      <td>0.633789</td>\n",
              "      <td>2.302734</td>\n",
              "      <td>1.398438</td>\n",
              "      <td>-0.318604</td>\n",
              "      <td>-1.411133</td>\n",
              "      <td>-0.155273</td>\n",
              "      <td>0.277832</td>\n",
              "      <td>-0.706055</td>\n",
              "      <td>-0.780273</td>\n",
              "      <td>0.354004</td>\n",
              "      <td>0.618652</td>\n",
              "      <td>0.596191</td>\n",
              "      <td>-0.121765</td>\n",
              "      <td>0.667969</td>\n",
              "      <td>-0.057373</td>\n",
              "      <td>0.301514</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>-0.538574</td>\n",
              "      <td>-0.037201</td>\n",
              "      <td>-0.479980</td>\n",
              "      <td>-0.283936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>213605 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              V1        V2        V3  ...       V27       V28     Amount\n",
              "276544  2.019531 -0.099060 -1.123047  ... -0.016449 -0.048065  -0.071716\n",
              "168089 -0.815918 -0.408203 -1.699219  ... -0.099182  0.199829   6.621094\n",
              "91651  -1.185547  1.182617  1.567383  ... -0.141479 -0.355225  -0.141235\n",
              "258071  1.817383 -0.727539 -0.291504  ... -0.038666 -0.049530   0.670898\n",
              "167236 -1.670898 -7.312500 -2.699219  ... -0.369873  0.313232  27.687500\n",
              "...          ...       ...       ...  ...       ...       ...        ...\n",
              "194533 -0.917480  0.855469  1.515625  ... -0.068481  0.048981   0.173462\n",
              "163532 -0.818848 -0.653809  1.685547  ... -0.277344 -0.461914   1.102539\n",
              "47169   0.984375 -0.951660  0.760742  ...  0.045746  0.061768   2.070312\n",
              "138367  0.699707 -1.557617  0.286865  ... -0.065369  0.075745   4.429688\n",
              "271    -0.351318  1.183594  0.530762  ... -0.037201 -0.479980  -0.283936\n",
              "\n",
              "[213605 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxmGQtTpEE1n",
        "outputId": "e865133d-242f-4eae-eb8a-2ca7ffefa6ce"
      },
      "source": [
        "X_test['Amount'] = rob_scaler.transform(X_test['Amount'].values.reshape(-1,1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRMYB48hFVQl",
        "outputId": "1dfe1a02-6eec-477c-8e30-c3468040705e"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state = 33)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning:\n",
            "\n",
            "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsNPMuR3FY_5",
        "outputId": "41881fd3-0478-4297-e043-4c1b7bfb5ab7"
      },
      "source": [
        "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)\n",
        "\n",
        "print('Before SMOTE oversampling X_train shape=',X_train.shape)\n",
        "print('After SMOTE oversampling X_train shape=',X_train_smote.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Before SMOTE oversampling X_train shape= (213605, 29)\n",
            "After SMOTE oversampling X_train shape= (426472, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Macwg1EHWy"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SPZz54ZEO6A"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, GridSearchCV"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoM5q2-YEtrG",
        "outputId": "9462cb3a-0ed0-4351-a177-04c135e2f002"
      },
      "source": [
        "dt = DecisionTreeClassifier(max_depth=3, class_weight='balanced')\n",
        "dt.fit(X_train_smote, y_train_smote)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight='balanced', criterion='gini',\n",
              "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJOp7aljFoLz"
      },
      "source": [
        "y_train_pred_DT = dt.predict(X_train_smote)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8vxYV0eFrgj",
        "outputId": "66ed8995-d816-4293-a017-b84a92ab23dd"
      },
      "source": [
        "print(classification_report(y_train_smote, y_train_pred_DT))\n",
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_train_smote, y_train_pred_DT, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95    213236\n",
            "           1       0.95      0.95      0.95    213236\n",
            "\n",
            "    accuracy                           0.95    426472\n",
            "   macro avg       0.95      0.95      0.95    426472\n",
            "weighted avg       0.95      0.95      0.95    426472\n",
            "\n",
            "Confusion Matrix - Training Dataset\n",
            "Predicted       0       1     All\n",
            "True                             \n",
            "0          203126   10110  213236\n",
            "1           11116  202120  213236\n",
            "All        214242  212230  426472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7xqx_s8GZ5i"
      },
      "source": [
        "y_test_DT_smote = dt.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBne7a2sGnrC",
        "outputId": "0547aa0e-56e1-4fb8-eee0-4ac8204886b4"
      },
      "source": [
        "print(classification_report(y_test, y_test_DT_smote))\n",
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_test, y_test_DT_smote, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98     71079\n",
            "           1       0.03      0.85      0.06       123\n",
            "\n",
            "    accuracy                           0.95     71202\n",
            "   macro avg       0.52      0.90      0.52     71202\n",
            "weighted avg       1.00      0.95      0.97     71202\n",
            "\n",
            "Confusion Matrix - Training Dataset\n",
            "Predicted      0     1    All\n",
            "True                         \n",
            "0          67759  3320  71079\n",
            "1             19   104    123\n",
            "All        67778  3424  71202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPUHKqSkHcPo",
        "outputId": "ae689b72-c16d-428e-bc9d-4a2e8f7557a7"
      },
      "source": [
        "roc_auc_score(y_train_smote.ravel(), y_train_pred_DT)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9502288544148269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydm4nK52HuCC"
      },
      "source": [
        "y_train_pred_proba_DT_smote = dt.predict_proba(X_train_smote)[:,1]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eJ6oYWL-HnGB",
        "outputId": "aff98959-23cb-4448-f4e7-01db818e08c9"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_train_smote.ravel(),y_train_pred_proba_DT_smote)\n",
        "roc_auc = auc(fpr,tpr)\n",
        "\n",
        "# Plot ROC\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([-0.1,1.0])\n",
        "plt.ylim([-0.1,1.01])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}